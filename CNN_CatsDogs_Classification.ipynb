{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyUjJBcQlpXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b853c2c-1811-4508-a953-380a27d8237c"
      },
      "source": [
        "#get acess google drive data into google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_056H6sxzGR",
        "outputId": "feaa2fea-04b7-4ce3-a53e-1d0ac0cc8241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyAJpSLXoLDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e07b054-aea6-416c-852f-5958ea996aee"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/dataset.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('finish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0013vj7Eo_Qh"
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQmd9c1npKFF"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the CNN\n",
        "\n",
        "CNN_Classifier=Sequential();\n",
        "\n",
        "# Step 1 - Convolution\n",
        "CNN_Classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Step 1 - Convolution\n",
        "CNN_Classifier.add(Conv2D(16,(3,3),activation='relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "# Step 3 - Flattening\n",
        "CNN_Classifier.add(Flatten())\n",
        "\n",
        "\n",
        "# Step 4 - Full connection\n",
        "\n",
        "CNN_Classifier.add(Dense(units=128, activation='relu'))\n",
        "CNN_Classifier.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the CNN\n",
        "CNN_Classifier.compile(optimizer ='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOPgO_BVsa_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be561df7-92cf-4daa-cc90-b0153937c07b"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "CNN_Classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = 7000,\n",
        "                         epochs = 10,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 2000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-5787c2ac704a>:20: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  CNN_Classifier.fit_generator(training_set,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 250/7000 [>.............................] - ETA: 23:08 - loss: 0.5829 - accuracy: 0.6904"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7000/7000 [==============================] - 62s 9ms/step - loss: 0.5829 - accuracy: 0.6904 - val_loss: 0.6037 - val_accuracy: 0.6950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef057ea8700>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img(\"/content/dataset/single_prediction/cat_or_dog_1.jpg\",target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=CNN_Classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0]==1:\n",
        "  prediction='Dog'\n",
        "  print(prediction)\n",
        "else:\n",
        "  prediction='Cat'\n",
        "  print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BndJ1EYF0vPq",
        "outputId": "86bcd4ba-5f8e-4797-b971-c8a18e1244a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img(\"/content/dataset/single_prediction/cat_or_dog_2.jpg\",target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=CNN_Classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0]==1:\n",
        "  prediction='Dog'\n",
        "  print(prediction)\n",
        "else:\n",
        "  prediction='Cat'\n",
        "  print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc7W5QyQ2jbJ",
        "outputId": "65d520be-a610-4e87-cb1b-88e4870c7e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n",
            "Cat\n"
          ]
        }
      ]
    }
  ]
}